# ğŸ“Š Introduction to Pandas

Pandas is a powerful open-source Python library used for data analysis and manipulation. It is built on top of NumPy and provides easy-to-use data structures like:

- **Series**: One-dimensional labeled arrays.
- **DataFrame**: Two-dimensional labeled data structures (like a spreadsheet or SQL table).

Pandas allows you to:
- Load and explore datasets from various sources (CSV, Excel, SQL, etc.)
- Clean, filter, and transform data efficiently
- Perform complex data analysis and aggregations with minimal code


## ğŸ§± Pandas Series

A **Series** is a one-dimensional labeled array that can hold any data type â€” integers, strings, floats, Python objects, etc.

Itâ€™s like a column in a spreadsheet or database.

### âœ… Creating a Series

```python
import pandas as pd

# From a list
data = [10, 20, 30, 40]
s = pd.Series(data)
print(s)

# Output :0    10
1    20
2    30
3    40
dtype: int64
```
You can also set custom labels (index):

```python
s = pd.Series([10, 20, 30], index=['a', 'b', 'c'])
print(s)

# Output:
a    10
b    20
c    30
dtype: int64
```

### ğŸ” Accessing Elements

```python
print(s['a'])     # Access by label â†’ 10
print(s[0])       # Access by position â†’ 10
```

ğŸ› ï¸ Useful Attributes and Methods
```python
s.values      # returns array([10, 20, 30])
s.index       # returns Index(['a', 'b', 'c'], dtype='object')
s.sum()       # returns 60
s.mean()      # returns 20.0
```



---


## ğŸ§© Pandas DataFrame

A **DataFrame** is a two-dimensional, size-mutable, and heterogeneous data structure with labeled axes (rows and columns). Think of it like a table in SQL or an Excel spreadsheet.

### âœ… Creating a DataFrame

```python
import pandas as pd

# From a dictionary
data = {
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35],
    'City': ['New York', 'Paris', 'London']
}

df = pd.DataFrame(data)
print(df)


# Output:
     Name  Age      City
0   Alice   25  New York
1     Bob   30     Paris
2  Charlie   35    London
```


---


### ğŸ” Accessing Data in a DataFrame

Pandas offers flexible ways to access data from a DataFrame, whether by column, row, or individual cell.

---

#### ğŸ“Œ Accessing Columns
```python
df['Name']           # Access a single column
df[['Name', 'Age']]  # Access multiple columns
```

#### ğŸ“Œ Accessing Rows

```python
df.iloc[0]      # Access by row index (integer location)
df.loc[0]       # Access by row label (same as iloc if default index)
```
- iloc[] is used for positional indexing (0-based).
- loc[] is used for label-based indexing (especially after custom indexing).


#### ğŸ“Œ Accessing a Cell
```python
df.loc[1, 'City']     # Get value from row 1, column 'City'
df.iloc[1, 2]         # Same using position (row 1, column 2)
```
- Combines row and column access.
- Returns a single value (scalar).


---



### ğŸ§  Descriptive Statistics in Pandas

Pandas provides powerful built-in functions to quickly understand your dataset.

---

#### ğŸ“Š `df.describe()`
Returns a summary of statistics for numeric columns, including:
- **count** â€“ Number of non-null values
- **mean** â€“ Average value
- **std** â€“ Standard deviation
- **min**, **25%**, **50% (median)**, **75%**, **max** â€“ Distribution percentiles

```python
df.describe()
```

â„¹ï¸ df.info()

- Gives a concise summary of the DataFrame:
- Number of entries
- Column names and data types
- Non-null counts
- Memory usage

```python 
df.info()
```


ğŸ‘€ df.head(n) / df.tail(n)
- df.head() returns the first n rows (default = 5)
- df.tail() returns the last n rows (default = 5)

```python
df.head()
df.tail(3)
```

---


## ğŸ“¥ Loading Data in Pandas

Pandas makes it easy to load data from different file formats like CSV, Excel, and more.

---

### ğŸ“„ Loading CSV Files

```python
import pandas as pd

df = pd.read_csv('data.csv')
print(df.head())
```
- read_csv() is the most common way to import tabular data.
- df.head() shows the first 5 rows to give a quick overview.
- CSV files are widely used in data science for storing structured data.


---


## ğŸ” Filtering Data in Pandas

Filtering allows you to select rows that meet certain conditions â€” similar to WHERE clauses in SQL.

This is useful when you only want to work with specific subsets of your data, like finding users above a certain age, or products with high sales.

---

### ğŸ§ª Example: Filtering with Conditions

```python
import pandas as pd

data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': [25, 32, 30, 28],
    'City': ['NY', 'Paris', 'London', 'NY']
}

df = pd.DataFrame(data)

# Filter: People older than 28
df[df['Age'] > 28]
```


### ğŸ”— Combining Multiple Conditions
```python
# AND condition
df[(df['Age'] > 28) & (df['City'] == 'NY')]

# OR condition
df[(df['Age'] > 28) | (df['City'] == 'Paris')]
```
- Use & for AND, | for OR
- Wrap each condition in parentheses!


### â“ Filtering by Text Match
```python
df[df['City'] == 'NY']
```


### ğŸ” Filtering Using .isin() and .str.contains()
```python
# Using isin() for multiple values
df[df['City'].isin(['NY', 'London'])]

# Using string matching
df[df['Name'].str.contains('li')]
```


---



## ğŸ”ƒ Sorting Data in Pandas

Sorting helps organize your data and makes it easier to analyze trends, rankings, and outliers.

You can sort by one or multiple columns in ascending or descending order.

---

### ğŸ”¢ Sorting by One Column

```python
df.sort_values(by='Age')
```
- Sorts the DataFrame based on the 'Age' column in ascending order (default).

### ğŸ”» Sorting in Descending Order
```python
df.sort_values(by='Age', ascending=False)
```
- Set ascending=False to sort from largest to smallest.


### ğŸ”— Sorting by Multiple Columns
```python
df.sort_values(by=['City', 'Age'])
```
- Sorts first by 'City', then by 'Age' within each city group.


### âš™ï¸ Sorting Index Instead of Values
```python
df.sort_index()
```
- Sorts the DataFrame by the row index.

**Sorting is especially useful when you're ranking data, preparing reports, or want to visually inspect ordered data.**



---


## ğŸ©¹ Handling Missing Data in Pandas

In real-world datasets, missing or null values are common. Pandas provides simple tools to detect, remove, or fill them.

---

### ğŸ” Detecting Missing Values

```python
df.isnull()
```
- Returns a DataFrame of the same shape with True where values are missing.

```python
  df.isnull().sum()
```
- Counts missing values column-wise.

### ğŸ§¹ Dropping Missing Data
```python
df.dropna()
```
- Removes rows with any missing values.

```python
df.dropna(axis=1)
```
- Remove column with any missing values.

### ğŸ§ª Filling Missing Data
```python
df.fillna(0)
```
- Replaces all missing values with 0.

```python
df.fillna(method='ffill')  # forward fill
df.fillna(method='bfill')  # backward fill
```
- Propagates the next or previous valid value.

### ğŸ¯ Replacing Specific Values
```python
df.replace(to_replace='?', value=np.nan)
```
- Useful when missing values are denoted by symbols like '?' or 'N/A'.

**Handling missing values properly ensures clean and reliable data analysis.**


---


## ğŸ“Š Grouping and Aggregation in Pandas

Grouping and aggregation allow you to summarize your data â€” like calculating averages, counts, or sums grouped by a specific category.

This is especially useful in analyzing sales, survey results, user behavior, etc.

---

### ğŸ‘¥ Grouping by a Column

```python
df.groupby('City')
```
- Groups rows based on the values in the 'City' column.

### ğŸ”¢ Aggregating with Functions
```python
df.groupby('City')['Age'].mean()
```
- Calculates the average 'Age' for each 'City'.

```python
df.groupby('City').sum()
```
- Sums all numerric columns grouped by 'City'.

### ğŸ§  Common Aggregation Functions
- .mean() â€“ Average
- .sum() â€“ Total
- .count() â€“ Number of items
- .min() / .max() â€“ Minimum / Maximum
- .median() â€“ Median value

### ğŸ›ï¸ Multiple Aggregations
```python
df.groupby('City')['Age'].agg(['mean', 'min', 'max'])
```
- Apply multiple aggregation functions at once.

**Grouping and aggregation simplify complex data into meaningful summaries.**


---


## ğŸ”— Merging and Joining DataFrames in Pandas

Often, data is split across multiple tables. Pandas allows you to combine them efficiently using merges and joins â€” similar to SQL operations.

---

### ğŸ”„ Merging Two DataFrames

```python
pd.merge(df1, df2, on='id')
```
- Merges df1 and df2 where the values in the 'id' column match.

### ğŸ§­ Types of Joins
```python
pd.merge(df1, df2, how='inner', on='id')   # Only matching rows
pd.merge(df1, df2, how='left', on='id')    # All from df1, match from df2
pd.merge(df1, df2, how='right', on='id')   # All from df2, match from df1
pd.merge(df1, df2, how='outer', on='id')   # All rows, matched when possible
```

### ğŸ§± Joining on Index
```python
df1.join(df2, how='inner')
```
- Combines DataFrames using their indexes instead of a specific column.

### ğŸ› ï¸ Concatenating DataFrames
```python
pd.concat([df1, df2])
```
- Stacks DataFrames vertically (row-wise) or horizontally (column-wise using axis=1).

**Merging and joining are crucial when integrating data from multiple sources like databases, APIs, or separate CSV files.**
